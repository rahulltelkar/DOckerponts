ORCHESTRATION:
---------------------------------------------------------------------------------------------------------------------------------------------------------
1. Swarm services use a declarative model
2. To confirm that the service was created and started successfully, use the docker service ls
3. To provide a name for your service, use the --name flag: docker service create --name my_web nginx
4. gMSA credential spec - a requirement for Active Directory-authenticated applications. 
   This reduces the burden of distributing credential specs to the nodes they’re used on.
5. To use a Config as a credential spec, first create the Docker Config containing the credential spec: docker config create credspec credspec.json
6. you can create a service using this credential spec. To do so, use the --credential-spec flag with the config name, like this: docker service create --credential-spec="config://credspec" <your image>
7. If your image is available on a private registry which requires login, use the --with-registry-auth flag with docker service create
8. If your image is stored on registry.example.com, which is a private registry, use a command like the docker login registry.example.com
9. Credential spec files are applied at runtime.
10. no gMSA credentials are written to disk on worker nodes.
11. When deploying a service using a gMSA-based config, the credential spec is passed directly to the runtime of containers in that service.
12. To use a Config as a credential spec, create a Docker Config in a credential spec file named credpspec.json.
13. You can change almost everything about an existing service using the docker service update command. 
14. Since Nginx is a web service, it works much better if you publish port 80 to clients outside the swarm. You can specify this when you create the service, using the -p or --publish flag.
15. When updating an existing service, the flag is --publish-add. Assuming that the my_web service from the previous section still exists, use the following command to update it to publish port 80.
       docker service update --publish-add 80 my_web
16. here is also a --publish-rm flag to remove a port that was previously published.
17. To remove a service, use the docker service remove command.
18. If you specify a tag, the manager resolves that tag to a digest.
19. When the request to create a container task is received on a worker node, the worker node only sees the digest, not the tag.
20. When you create a service, the image’s tag is resolved to the specific digest the tag points to at the time of service creation.
21. If the manager can’t resolve the tag to a digest, each worker node is responsible for resolving the tag to a digest, and different nodes may use different versions of the image.
22. To see an image’s current digest, issue the command docker inspect <IMAGE>:<TAG> and look for the RepoDigests line.
23. If the swarm manager can resolve the image tag to a digest, it instructs the worker nodes to redeploy the tasks and use the image at that digest.
24. When you create a swarm service, you can publish that service’s ports to hosts outside the swarm in two ways: 
       i. You can rely on the routing mesh.  ii. You can publish a service task’s port directly on the swarm node .
25. Routing mesh: When you publish a service port, the swarm makes the service accessible at the target port on every node, regardless of whether there is a task for the service running on that node or not. This is less complex and is the right choice for many types of services.
26. PUBLISH A SERVICE’S PORTS USING THE ROUTING MESH: To publish a service’s ports externally to the swarm, use the --publish <PUBLISHED-PORT>:<SERVICE-PORT> flag
27. If an external host connects to that port on any swarm node, the routing mesh routes it to a task.
28. The external host does not need to know the IP addresses or internally-used ports of the service tasks to interact with the service. When a user or process connects to a service, any worker node running a service task may respond.
29. PUBLISH A SERVICE’S PORTS DIRECTLY ON THE SWARM NODE: You can publish a service task’s port directly on the swarm node where that service is running.
30. PUBLISH A SERVICE’S PORTS DIRECTLY ON THE SWARM NODE: provides the maximum flexibility, including the ability for you to develop your own routing framework.
31. To publish a service’s port directly on the node where it is running, use the mode=host option to the --publish flag.
32. create overlay network on a manager node using the docker network create command with the --driver overlay flag.
33. You can create a new service and pass the --network flag to attach the service to the overlay network: 
    docker service create \
  --replicas 3 \
  --network my-network \
  --name my-web \
    nginx
34. You can also connect an existing service to an overlay network using the --network-add flag. docker service update --network-add my-network my-web.
35. To disconnect a running service from a network, use the --network-rm flag.: docker service update --network-rm my-network my-web.
36. Placement constraints let you configure the service to run only on nodes with specific (arbitrary) metadata set, and cause the deployment to fail if appropriate nodes do not exist. 
37. you can specify that your service should only run on nodes where an arbitrary label pci_compliant is set to true.
38. Placement preferences let you apply an arbitrary label with a range of values to each node, and spread your service’s tasks across those nodes using an algorithm.
39. Swarm mode has two types of services: replicated and global.
40. For replicated services, you specify the number of replica tasks for the swarm manager to schedule onto available nodes.
41. For global services, the scheduler places one task on each available node that meets the service’s placement constraints and resource requirements.
42. I created a deployment that runs several identical tasks on nodes. which type of service deployment is this?: Replicated.
43. I created a deployment that runs exactly one task on every node. which type of service deployment is this? Global.
44. You control the type of service using the --mode flag. If you don’t specify a mode, the service defaults to replicated.
44. For replicated services, you specify the number of replica tasks you want to start using the --replicas flag. For example, to start a replicated nginx service with 3 replica tasks:
     docker service create \
  --name my_web \
  --replicas 3 \
  nginx
45. To start a global service on each available node, pass --mode global to docker service create.
46. The global service on the new node.
      docker service create \
  --name myservice \
  --mode global \
    alpine top
47. To reserve a given amount of memory or number of CPUs for a service, use the --reserve-memory or --reserve-cpu flags.
48. PLACEMENT CONSTRAINTS: service only runs on nodes with the label region set to east. If no appropriately-labelled nodes are available, tasks will wait in Pending  until they become available.
49. PLACEMENT CONSTRAINTS: The --constraint flag uses an equality operator (== or !=)
     docker service create \
  --name my-nginx \
  --replicas 5 \
  --constraint node.labels.region==east \
  nginx
50. PLACEMENT PREFERENCES: While placement constraints limit the nodes a service can run on, placement preferences try to place tasks on appropriate nodes in an algorithmic way (currently, only spread evenly). 
      docker service create \
  --replicas 9 \
  --name redis_2 \
  --placement-pref 'spread=node.labels.datacenter' \
  redis:3.0.6
  
51. When updating a service with docker service update, --placement-pref-add appends a new placement preference after all existing placement preferences.
52. --placement-pref-rm removes an existing placement preference that matches the argument.
53. The --update-delay flag configures the time delay between updates to a service task or sets of tasks.
54. By default the scheduler updates 1 task at a time. You can pass the --update-parallelism flag to configure the maximum number of service tasks that the scheduler updates simultaneously.
55. When an update to an individual task returns a state of RUNNING, the scheduler continues the update by continuing to another task until all tasks are updated. If, at any time during an update a task returns FAILED, the scheduler pauses the update.
    You can control the behavior using the --update-failure-action flag for docker service create or docker service update.
56. When an updated task returns either RUNNING or FAILED, the scheduler waits 10 seconds before stopping the next task to update:
      docker service create \
  --replicas 10 \
  --name my_web \
  --update-delay 10s \
  --update-parallelism 2 \
  --update-failure-action continue \
  alpine
57. The --update-max-failure-ratio flag controls what fraction of tasks can fail during an update before the update as a whole is considered to have failed. 
58. An individual task update is considered to have failed if the task doesn’t start up, or if it stops running within the monitoring period specified with the --update-monitor flag.
59. The default value for --update-monitor is 30 seconds.
60. In case the updated version of a service doesn’t function as expected, it’s possible to manually roll back to the previous version of the service using docker service update’s --rollback flag.
61. You can create two types of mounts for services in a swarm, volume mounts or bind mounts.
62. using the --mount flag when you create a service. the --mount-add or --mount-rm flag when updating an existing service. 
63. Data volumes are storage that exist independently of a container.
64. Volumes can be created before deploying a service, or if they don’t exist on a particular host when a task is scheduled there, they are created automatically according to the volume specification on the service. 
65. The default volume driver is local.
66.  To use a different volume driver with this create-on-demand pattern, specify the driver and its options with the --mount flag
67. Bind mounts are file system paths from the host where the scheduler deploys the container for the task. 
     docker service create \
  --mount type=bind,src=<HOST-PATH>,dst=<CONTAINER-PATH> \     /// READ-WRITE BIND.
  --name myservice \
  <IMAGE>
68. docker service create \
  --mount type=bind,src=<HOST-PATH>,dst=<CONTAINER-PATH>,readonly \   ///READ-ONLY
  --name myservice \
  <IMAGE>
69. Bind mounts can be useful but they can also cause problems. The main risks include the following:
      i. If you bind mount a host path into your service’s containers, the path must exist on every swarm node.The Docker swarm mode scheduler can schedule containers on any machine that meets resource availability requirements and satisfies all constraints and placement preferences you specify
      ii. The Docker swarm mode scheduler may reschedule your running service containers at any time if they become unhealthy or unreachable.
	  iii. Host bind mounts are non-portable. When you use bind mounts, there is no guarantee that your application runs the same way in development as it does in production.
70. The following flags are supported for template:
      --hostname
      --mount
      --env	  
71. docker node update [OPTIONS] NODE: 
     --availability ->Availability of the node (“active”|”pause”|”drain”)
     --label-add->Add or update a node label (key=value) 
     --label-rm->Remove a node label if exists	 
     --role->Role of the node (“worker”|”manager”)
72. Add metadata to a swarm node using node labels.  $ docker node update --label-add foo worker1
73. To add multiple labels to a node, pass the --label-add flag for each label: $ docker node update --label-add foo --label-add bar worker1
74. When you create a service, you can use node labels as a constraint. A constraint limits the nodes where the scheduler deploys tasks for a service.
         $ docker node update --label-add type=queue worker1    ///where type is a label and queue is service.
75. Open a terminal and ssh into the machine where you want to run your manager node. you can connect to it via SSH using the  command:
        $ docker-machine ssh manager1
76. Run the command to create a new swarm: $ docker swarm init --advertise-addr <MANAGER-IP>
77. The --advertise-addr flag configures the manager node to publish its address as 192.168.99.100. The other nodes in the swarm must be able to access the manager at the IP address.
78. Run docker info to view the current state of the swarm:
79. Run the docker node ls command to view information about nodes:
80. you can run the following command on a manager node to retrieve the join command for a worker: docker swarm join-token worker.
81. STACK must be executed on a swarm manager node.
82. The Compose file is a YAML file defining services, networks and volumes. The default path for a Compose file is ./docker-compose.yml.
83. restart: no is the default restart policy, and it does not restart a container under any circumstance. When always is specified, the container always restarts.
     The on-failure policy restarts a container if the exit code indicates an on-failure error and restart: unless-stopped
            restart: "no"
            restart: always
            restart: on-failure
            restart: unless-stopped
84. The restart option is ignored when deploying a stack in swarm mode.
85. The Raft logs used by swarm managers are encrypted on disk by default.
86. When Docker restarts, both the TLS key used to encrypt communication among swarm nodes, and the key used to encrypt and decrypt Raft logs on disk, are loaded into each manager node’s memory.
87. Ability to protect the mutual TLS encryption key and the key used to encrypt and decrypt Raft logs at rest, by allowing you to take ownership of these keys and to require manual unlocking of your managers. This feature is called autolock.
88. When Docker restarts, you must unlock the swarm first, using a key encryption key generated by Docker when the swarm was locked. You can rotate this key encryption key at any time.
89. You don’t need to unlock the swarm when a new node joins the swarm, because the key is propagated to it over mutual TLS.
90. When you initialize a new swarm, you can use the --autolock flag to enable autolocking of swarm manager nodes when Docker restarts.
                $ docker swarm init --autolock.
91. To enable autolock on an existing swarm, set the autolock flag to true: $ docker swarm update --autolock=true
92. To disable autolock, set --autolock to false. $ docker swarm update --autolock=false.
93. To unlock a locked swarm, use docker swarm unlock. : $ docker swarm unlock
94. If the key has not been rotated since the node left the swarm, and you have a quorum of functional manager nodes in the swarm, you can view the current unlock key using
         $ docker swarm unlock-key
95. docker swarm unlock-key --rotate
96. $ docker service ls

	ID            NAME        SCALE  IMAGE   COMMAND
	9uk4639qpg7n  helloworld  1/1    alpine  ping docker.com
97. A task is the atomic unit of scheduling within a swarm.
98. The container is the instantiation of the task.
99. API: accepts command and  create service object.
100. orchestrator: reconsillation loop that creates tasks for service object.
111. allocater:  allocates IP address to task.
112. dispatcher: assign task to nodes.
113. scheduler: instructs a worker to run a task. 
114. If your only intention is to prevent a service from being deployed, scale the service to 0 instead of trying to configure it in such a way that it remains in pending.
115. If all nodes are paused or drained, and you create a service, it is pending until a node becomes available.
116. The first node to become available gets all of the tasks, so this is not a good thing to do in a production environment.   
117. You can reserve a specific amount of memory for a service. If no node in the swarm has the required amount of memory, the service remains in a pending state until a node is available which can run its tasks.
118. For a replicated service, you specify the number of identical tasks you want to run. For example, you decide to deploy an HTTP service with three replicas, each serving the same content.
119. A global service is a service that runs one task on every node. There is no pre-specified number of tasks.
120: Running Services on a Docker Swarm can be scaled in different ways: docker service scale SERVICE=NUMBER. This works only for replicated services. 
       Another way is using docker service update --replicas=NUMBER SERVICE to achieve the same goal.
121. multiple services can be scaled at once, using the docker service scale SERVICE1=NUMBER1 SERVICE2=NUMBER2
122. docker inspect: Return low-level information on Docker objects. Docker inspect provides detailed information on constructs controlled by Docker.
123. By default, docker inspect will render results in a JSON array.
124. Run docker service inspect --pretty <SERVICE-ID> to display the details about a service in an easily readable format.
125. Run docker service ps <SERVICE-ID> to see which nodes are running the service.
126. By default, manager nodes in a swarm can execute tasks just like worker nodes.
127. docker stack ls shows an overview of all existing stacks.
128. docker stack ps STACK lists all tasks in a stack.
129. docker stack services STACK gives an overview over the running services.
130. docker stack rm STACK removes one or more stack.
131. Swarm manager nodes use the Raft Consensus Algorithm to manage the swarm state.
132. manager nodes are the key components for managing the swarm and storing the swarm state.
133. More Manager nodes reduce write performance because more nodes must acknowledge proposals to update the swarm state. This means more network round-trip traffic.
134. Raft requires a majority of managers, also called the quorum.
135. If the swarm loses the quorum of managers, the swarm cannot perform management tasks.
136. Even if a swarm loses the quorum of managers, swarm tasks on existing worker nodes continue to run. However, swarm nodes cannot be added, updated, or removed, and new or existing tasks cannot be started, stopped, moved, or updated.
137. Scaling down to a single manager is an unsafe operation and is not recommended.
138. If the last node leaves the swarm unexpectedly during the demote operation, the swarm becomes unavailable until you reboot the node or restart with --force-new-cluster.
139. By default manager nodes also act as a worker nodes. This means the scheduler can assign tasks to a manager node.
140. To avoid interference with manager node operation, you can drain manager nodes to make them unavailable as worker nodes:
           docker node update --availability drain <NODE>
141. When you drain a node, the scheduler reassigns any tasks running on the node to other available worker nodes in the swarm. It also prevents the scheduler from assigning tasks to the node.
142. You can monitor the health of manager nodes by querying the docker nodes API in JSON format through the /nodes HTTP endpoint
      docker node inspect manager1 --format "{{ .ManagerStatus.Reachability }}"
      reachable
       
      docker node inspect manager1 --format "{{ .Status.State }}"
      ready

142. An unreachable health status means that this particular manager node is unreachable from other manager nodes. In this case you need to take action to restore the unreachable manager:

     Restart the daemon and see if the manager comes back as reachable.     
     Reboot the machine.
     If neither restarting or rebooting work, you should add another manager node or promote a worker to be a manager node. You also need to cleanly remove the failed node entry from the manager set with docker node demote <NODE> and docker node rm <id-node>.
143. You should never restart a manager node by copying the raft directory from another node. The data directory is unique to a node ID. 
     A node can only use a node ID once to join the swarm. The node ID space should be globally unique.
145. To cleanly re-join a manager node to a cluster:

	To demote the node to a worker, run docker node demote <NODE>.
	To remove the node from the swarm, run docker node rm <NODE>.
	Re-join the node to the swarm with a fresh state using docker swarm join.
146. remove a node: docker node rm
147. you can forcefully remove the node without shutting it down by passing the --force flag. docker node rm --force node9
148. Before you forcefully remove a manager node, you must first demote it to the worker role. Make sure that you always have an odd number of manager nodes if you demote or remove a manager.
149. Docker manager nodes store the swarm state and manager logs in the /var/lib/docker/swarm/ directory.
150. You can back up the swarm using any manager. Use the following procedure. 
	1. If the swarm has auto-lock enabled, you need the unlock key to restore the swarm from backup. 
        Retrieve the unlock key if necessary and store it in a safe location. If you are unsure, read Lock your swarm to protect its encryption key.
        2. Stop Docker on the manager before backing up the data, so that no data is being changed during the backup. 
        It is possible to take a backup while the manager is running (a “hot” backup), but this is not recommended and your results are less predictable when restoring. While the manager is down, other nodes continue generating swarm data that is not part of this backup.
	3. Back up the entire /var/lib/docker/swarm directory.
        4. Restart the manager.
151. Recover from disaster: Restore from a backup.
        1. Shut down Docker on the target host machine for the restored swarm.
        2. Remove the contents of the /var/lib/docker/swarm directory on the new swarm.
        3. Restore the /var/lib/docker/swarm directory with the contents of the backup.
	4. Start Docker on the new node. Unlock the swarm if necessary. Re-initialize the swarm using the following command, 	
           so that this node does not attempt to connect to nodes that were part of the old swarm, and presumably no longer exist. $ docker swarm init --force-new-cluster
	5. Verify that the state of the swarm is as expected. This may include application-specific tests or simply checking the output of docker service ls to be sure that all expected services are present.
	6. If you use auto-lock, rotate the unlock key.
	7. Add manager and worker nodes to bring your new swarm up to operating capacity.
	8. Reinstate your previous backup regimen on the new swarm.
152. swarm cannot automatically recover if it loses a quorum.
153. The swarm can tolerate up to (N-1)/2 permanent failures beyond which requests involving swarm management cannot be processed.
154. The best way to recover from losing the quorum is to bring the failed nodes back online. If you can’t do that, the only way to recover from this state is to use the --force-new-cluster action from a manager node.
155.  you can use the --force or -f flag with the docker service update command to force the service to redistribute its tasks across the available worker nodes. 
156. When the container starts, it can only be connected to a single network, using --network
157. you can connect a running container to multiple networks using docker network connect.
158. container’s hostname defaults to be the container’s ID in Docker.
159. can override the hostname using --hostname.
-------------------------------------------------------------------------------------------------------------------------------------------------------------
IMAGE MANAGEMENT AND REGISTRY.

1. Build an image from a Dockerfile
2. The results of the health checks are available at the /debug/health endpoint on the debug HTTP server if the debug HTTP server is enabled.
3. You can delete an image from the Docker Hub by deleting individual tags in your repository in the tags area.
4. An image may be deleted from the registry via its name and reference. A delete may be issued with the following request format: DELETE /v2/<name>/manifests/<reference>
5. Tag Image: docker image tag SOURCE_IMAGE[:TAG] TARGET_IMAGE[:TAG]
6. docker image build: Build an image from a Dockerfile, docker image import: Import the contents from a tarball to create a filesystem image. docker image load: Load an image from a tar archive or STDIN. docker image save: Save one or more images to a tar archive (streamed to STDOUT by default).
7. The Registry is a stateless, highly scalable server side application that stores and lets you distribute Docker images. The Registry is open-source, under the permissive Apache license.
8. Start your registry: docker run -d -p 5000:5000 --name registry registry:2
9. Tag the image so that it points to your registry: docker image tag ubuntu localhost:5000/myfirstimage
10. Push it: Docker push localhost:5000/myfirstimage
11. Pull it back: docker pull localhost:5000/myfirstimage
12. Now stop your registry and remove all data: docker container stop registry && docker container rm -v registry
13. Docker can build images automatically by reading the instructions from a Dockerfile.
14. The docker build command builds an image from a Dockerfile and a context. 
15. The build is run by the Docker daemon, not by the CLI.
16. use the -f flag with docker build to point to a Dockerfile anywhere in your file system. $ docker build -f /path/to/a/Dockerfile .
17. You can specify a repository and tag at which to save the new image if the build succeeds: $ docker build -t shykes/myapp .
18. To tag the image into multiple repositories after the build, add multiple -t parameters when you run the build command:
      $ docker build -t shykes/myapp:1.0.2 -t shykes/myapp:latest .
19. Each instruction Dockerfile is run independently, and causes a new image to be created - so RUN cd /tmp will not have any effect on the next instructions.
20. Whenever possible, Docker will re-use the intermediate images (cache), to accelerate the docker build process significantly.
21. Build cache is only used from images that have a local parent chain. This means that these images were created by previous builds or the whole chain of images was loaded with docker load.
22. If you wish to use build cache of a specific image you can specify it with --cache-from option.Images specified with --cache-from do not need to have a parent chain and may be pulled from other registries.
23. To use the BuildKit backend, you need to set an environment variable DOCKER_BUILDKIT=1 on the CLI before invoking docker build.
24. A Dockerfile must begin with a `FROM` instruction. 
25. The FROM instruction specifies the Parent Image from which you are building.
26. FROM may only be preceded by one or more ARG instructions, which declare arguments that are used in FROM lines in the Dockerfile.
27. Parser directives do not add layers to the build, and will not be shown as a build step. Parser directives are written as a special type of comment in the form # directive=value.
     A single directive may only be used once.
28. Parser directives are not case-sensitive. However, convention is for them to be lowercase.
29.  The parser directives are supported are: syntax and esape.
30. Custom Dockerfile implementation allows you to:
        Automatically get bugfixes without updating the daemon
        Make sure all users are using the same implementation to build your Dockerfile
	Use the latest features without updating the daemon
	Try out new experimental or third-party features
31. The escape directive sets the character used to escape characters in a Dockerfile. If not specified, the default escape character is \.
32. The escape character is used both to escape characters in a line, and to escape a newline.
33. escaping is not performed in a RUN command, except at the end of a line.
34. Environment variables are notated in the Dockerfile either with $variable_name or ${variable_name}.
35. ${variable:-word} indicates that if variable is set then the result will be that value. If variable is not set then word will be the result.
36. ${variable:+word} indicates that if variable is set then word will be the result, otherwise the result is the empty string.
37. ENV abc=hello
    ENV abc=bye def=$abc
    ENV ghi=$abc
     will result in def having a value of hello, not bye. However, ghi will have a value of bye because it is not part of the same instruction that set abc to bye.   
38. docker CLI sends the context to the docker daemon.
39. The FROM instruction initializes a new build stage and sets the Base Image for subsequent instructions. As such, a valid Dockerfile must start with a FROM instruction.
40. ARG is the only instruction that may precede FROM in the Dockerfile
41. FROM can appear multiple times within a single Dockerfile to create multiple images or use one build stage as a dependency for another. 
42. Each FROM instruction clears any state created by previous instructions.
43. Optionally a name can be given to a new build stage by adding AS name to the FROM instruction. COPY --from=<name|index>
44. FROM instructions support variables that are declared by any ARG instructions that occur before the first FROM.
45. An ARG declared before a FROM is outside of a build stage, so it can’t be used in any instruction after a FROM.
46. RUN has 2 forms: 
     RUN <command> (shell form, the command is run in a shell, which by default is /bin/sh -c on Linux or cmd /S /C on Windows)
     RUN ["executable", "param1", "param2"] (exec form)
47. The RUN instruction will execute any commands in a new layer on top of the current image and commit the results. The resulting committed image will be used for the next step in the Dockerfile.
48. The exec form makes it possible to avoid shell string munging, and to RUN commands using a base image that does not contain the specified shell executable.
49. The default shell for the shell form can be changed using the SHELL command.
50. To use a different shell, other than ‘/bin/sh’, use the exec form passing in the desired shell. For example: RUN ["/bin/bash", "-c", "echo hello"]
51. The exec form is parsed as a JSON array, which means that you must use double-quotes (“) around words not single-quotes (‘).
52. The cache for RUN instructions can be invalidated by using the --no-cache flag.
53. The cache for RUN instructions can be invalidated by ADD and COPY instructions.
54. The CMD instruction has three forms:
	CMD ["executable","param1","param2"] (exec form, this is the preferred form)
	CMD ["param1","param2"] (as default parameters to ENTRYPOINT)
	CMD command param1 param2 (shell form)
55. There can only be one CMD instruction in a Dockerfile. If you list more than one CMD then only the last CMD will take effect.
56. The main purpose of a CMD is to provide defaults for an executing container. 
57. If CMD is used to provide default arguments for the ENTRYPOINT instruction, both the CMD and ENTRYPOINT instructions should be specified with the JSON array format.
58. CMD [ "echo", "$HOME" ] will not do variable substitution on $HOME. If you want shell processing then either use the shell form or execute a shell directly, for example: CMD [ "sh", "-c", "echo $HOME" ].
59. If you would like your container to run the same executable every time, then you should consider using ENTRYPOINT in combination with CMD. 
60. RUN actually runs a command and commits the result; CMD does not execute anything at build time, but specifies the intended command for the image.
61. The LABEL instruction adds metadata to an image.A LABEL is a key-value pair.
62. An image can have more than one label. You can specify multiple labels on a single line.
63. To view an image’s labels, use the docker image inspect command. You can use the --format option to show just the labels; docker image inspect --format='' myimage
64. The MAINTAINER instruction sets the Author field of the generated images.
65. The EXPOSE instruction informs Docker that the container listens on the specified network ports at runtime. 
66. The EXPOSE instruction does not actually publish the port.
67. To actually publish the port when running the container, use the -p flag on docker run to publish 
    and map one or more ports, or the -P flag to publish all exposed ports and map them to high-order ports.
68. By default, EXPOSE assumes TCP. You can also specify UDP: EXPOSE 80/udp.
69. The ENV instruction sets the environment variable <key> to the value <value>. 
70. The ENV instruction has two forms.
     The first form, ENV <key> <value>, will set a single variable to a value.
     The second form, ENV <key>=<value> ..., allows for multiple variables to be set at one time
71. You can view the valuesof ENV using docker inspect, and change them using docker run --env <key>=<value>.
72. ADD has two forms:
        ADD [--chown=<user>:<group>] <src>... <dest>
        ADD [--chown=<user>:<group>] ["<src>",... "<dest>"]
73. The ADD instruction copies new files, directories or remote file URLs from <src> and adds them to the filesystem of the image at the path <dest>.
74. COPY has two forms:
           COPY [--chown=<user>:<group>] <src>... <dest>
	   COPY [--chown=<user>:<group>] ["<src>",... "<dest>"]
75. The COPY instruction copies new files or directories from <src> and adds them to the filesystem of the container at the path <dest>.
76. If you build using STDIN (docker build - < somefile), there is no build context, so COPY can’t be used.
77. If you build by passing a Dockerfile through STDIN (docker build - < somefile), there is no build context, so the Dockerfile can only contain a URL based ADD instruction.
78. Optionally COPY accepts a flag --from=<name|index> that can be used to set the source location to a previous build stage (created with FROM .. AS <name>) that will be used instead of a build context sent by the user.
79. ENTRYPOINT has two forms:
          ENTRYPOINT ["executable", "param1", "param2"] The exec form, which is the preferred form
          ENTRYPOINT command param1 param2 The shell form:


80. An ENTRYPOINT allows you to configure a container that will run as an executable.
81. Only the last ENTRYPOINT instruction in the Dockerfile will have an effect.
82. Dockerfile should specify at least one of CMD or ENTRYPOINT commands.
83. ENTRYPOINT should be defined when using the container as an executable.
84. CMD should be used as a way of defining default arguments for an ENTRYPOINT command or for executing an ad-hoc command in a container.
85. CMD will be overridden when running the container with alternative arguments.
86. If CMD is defined from the base image, setting ENTRYPOINT will reset CMD to an empty value. In this scenario, CMD must be defined in the current image to have a value.
87. The VOLUME instruction creates a mount point with the specified name and marks it as holding externally mounted volumes from native host or other containers.
88. The value can be a JSON array, VOLUME ["/var/log/"], or a plain string with multiple arguments, such as VOLUME /var/log or VOLUME /var/log /var/db.
89. The USER instruction sets the user name (or UID) and optionally the user group (or GID) to use when running the image and for any RUN, CMD and ENTRYPOINT instructions that follow it in the Dockerfile.
90. The WORKDIR instruction sets the working directory for any RUN, CMD, ENTRYPOINT, COPY and ADD instructions that follow it in the Dockerfile.
91. The WORKDIR instruction can be used multiple times in a Dockerfile.
92. WORKDIR /a
    WORKDIR b
    WORKDIR c
    RUN pwd
           The output of the final pwd command in this Dockerfile would be /a/b/c.
93. The ARG instruction defines a variable that users can pass at build-time to the builder with the docker build command using the --build-arg <varname>=<value> flag.
94.  If a user specifies a build argument that was not defined in the Dockerfile, the build outputs a warning.
        [Warning] One or more build-args [foo] were not consumed.
95. A Dockerfile may include one or more ARG instructions. 
96. The ONBUILD instruction adds to the image a trigger instruction to be executed at a later time, when the image is used as the base for another build. 
97. The trigger will be executed in the context of the downstream build, as if it had been inserted immediately after the FROM instruction in the downstream Dockerfile.
98. Any build instruction can be registered as a trigger.
99. A list of all triggers is stored in the image manifest, under the key OnBuild. They can be inspected with the docker inspect command.
100. The STOPSIGNAL instruction sets the system call signal that will be sent to the container to exit : STOPSIGNAL signal
101. The HEALTHCHECK instruction has two forms:
         HEALTHCHECK [OPTIONS] CMD command (check container health by running a command inside the container)
         HEALTHCHECK NONE (disable any healthcheck inherited from the base image)
102. The HEALTHCHECK instruction tells Docker how to test a container to check that it is still working. 
103. When a container has a healthcheck specified, it has a health status in addition to its normal status. This status is initially starting. Whenever a health check passes, it becomes healthy (whatever state it was previously in). 
      After a certain number of consecutive failures, it becomes unhealthy.
104. The health check will first run interval seconds after the container is started, and then again interval seconds after each previous check completes.
105. If a single run of the check takes longer than timeout seconds then the check is considered to have failed.
106. It takes retries consecutive failures of the health check for the container to be considered unhealthy.
107. start period provides initialization time for containers that need time to bootstrap. 
108. 0: success - the container is healthy and ready for use. 1: unhealthy - the container is not working correctly. 2: reserved - do not use this exit code
109. Each layer is only a set of differences from the layer before it.
110. When you create a new container, you add a new writable layer on top of the underlying layers. This layer is often called the “container layer”. 
111. The major difference between a container and an image is the top writable layer.
112. When the container is deleted, the writable layer is also deleted. The underlying image remains unchanged.Because each container has its own writable container layer, and all changes are stored in this container layer.
113.  If you need multiple images to have shared access to the exact same data, store this data in a Docker volume and mount it into your containers.
114. To view the approximate size of a running container, you can use the docker ps -s command. 
115. size: the amount of data (on disk) that is used for the writable layer of each container.
116. virtual size: the amount of data used for the read-only image data used by the container plus the container’s writable layer size.
117. Following additional ways a container can take up disk space:

	Disk space used for log files if you use the json-file logging driver. This can be non-trivial if your container generates a large amount of logging data and log rotation is not configured.
	Volumes and bind mounts used by the container.
	Disk space used for the container’s configuration files, which are typically small.
	Memory written to disk (if swapping is enabled).
	Checkpoints, if you’re using the experimental checkpoint/restore feature. 
118. Copy-on-write is a strategy of sharing and copying files for maximum efficiency.
119. layers is stored in its own directory inside the Docker host’s local storage area. To examine the layers on the filesystem, list the contents of /var/lib/docker/<storage-driver>
120. The copy-on-write operation follows this rough sequence:
      Search through the image layers for the file to update. The process starts at the newest layer and works down to the base layer one layer at a time. When results are found, they are added to a cache to speed future operations.
    
      Perform a copy_up operation on the first copy of the file that is found, to copy the file to the container’s writable layer.
      Any modifications are made to this copy of the file, and the container cannot see the read-only copy of the file that exists in the lower layer.

121. Display layers of a Docker image: ocker image history [OPTIONS] IMAGE
122. docker image import: Import the contents from a tarball to create a filesystem image
123. Docker builds images automatically by reading the instructions from a Dockerfile.
124. When you issue a docker build command, the current working directory is called the build context.By default, the Dockerfile is assumed to be located here, but you can specify a different location with the file flag (-f).
125. Docker has the ability to build images by piping Dockerfile through stdin with a local or remote build context. 
126. Piping a Dockerfile through stdin can be useful to perform one-off builds without writing a Dockerfile to disk, or in situations where the Dockerfile is generated, and should not persist afterwards.
127. If you want to improve the build-speed by excluding some files from the build- context, refer to exclude with .dockerignore.
128. Multi-stage builds allow you to drastically reduce the size of your final image, without struggling to reduce the number of intermediate layers and files.
129. Only the instructions RUN, COPY, ADD create layers.   multi-stage builds,  only copy the artifacts you need into the final image.
130. If you do not want to use the cache at all, you can use the --no-cache=true option on the docker build command. 
131. Display detailed information on one or more images: docker image inspect [OPTIONS] IMAGE [IMAGE...]
132. Images that use the v2 or later format have a content-addressable identifier called a digest.
133. Can pull using a digest value. You can also reference by digest in create, run, and rmi commands, as well as the FROM image reference in a Dockerfile.
134. docker images --filter "dangling=true": shows untagged images.
135. docker rmi $(docker images -f "dangling=true" -q): remove untagged images. 
136. Log in to a Docker registry: docker login [OPTIONS] [SERVER]
137. docker login localhost:8080
138. You need to specify the credentials store in $HOME/.docker/config.json  to tell the docker engine to use it.
139. Export a container’s filesystem as a tar archive: docker export [OPTIONS] CONTAINER
140. Import the contents from a tarball to create a filesystem image: docker image import [OPTIONS] file|URL|- [REPOSITORY[:TAG]]
141. Pull from a different registry: $ docker pull myregistry.local:5000/testing/test-image
142. Push an image or a repository to a registry: docker image push [OPTIONS] NAME[:TAG]
143. you can delete an image with docker rmi or docker image rm.
144. List images: docker image ls [OPTIONS] [REPOSITORY[:TAG]]
145. Remove unused images: docker image prune [OPTIONS]
146. Search the Docker Hub for images: docker search [OPTIONS] TERM
147. Images are stored in collections, known as a repository, which is keyed by a name, as seen throughout the API specification.

 

















     



































































































   



	 
	 
	 
	 
	 
	 
	 
	 
	 
	 
	 
	 
	 
	 
	 
	 
	 
	 
	 
	 
	 
	 
	 
	 
	 
	 
	 
	 
	 


























